# Random Forest Classifier
Random forest is a popular supervised learning algorithm that can be used for both classification and regression problems in machine learning. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.

In Random Forest, instead of relying on one decision tree, the algorithm creates a forest of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset. The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting.

Random Forest has several advantages over other algorithms. It takes less training time as compared to other algorithms, predicts output with high accuracy even for large datasets, and can maintain accuracy when a large proportion of data is missing.

## Implementation
- Importing the required Libraries
- Reading the dataset
- Performing EDA on the dataset
- Checking for outliers
- Encoding the Categorical Variables 
- Normalization of the data
- Splitting the data into Train and Test data
- K-Fold Cross Validation
- Building Model using Random Forest Classifier
- Conclusion
